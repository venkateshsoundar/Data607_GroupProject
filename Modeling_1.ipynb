{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('finalised_obesity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Gender', 'Age', 'family_history_with_overweight', 'FAVC',\n",
       "       'SMOKE', 'CH2O', 'SCC', 'CALC', 'MTRANS', 'obesity_level', 'BMI',\n",
       "       'SedentaryScore', 'DietScore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'NObeyesdad': 'obesity_level'})\n",
    "df= df.drop(columns={'Unnamed: 0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>obesity_level</th>\n",
       "      <th>BMI</th>\n",
       "      <th>SedentaryScore</th>\n",
       "      <th>DietScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "      <td>24.386526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "      <td>24.238227</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "      <td>23.765432</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "      <td>26.851852</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "      <td>28.342381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age family_history_with_overweight FAVC SMOKE  CH2O  SCC  \\\n",
       "0  Female  21.0                            yes   no    no   2.0   no   \n",
       "1  Female  21.0                            yes   no   yes   3.0  yes   \n",
       "2    Male  23.0                            yes   no    no   2.0   no   \n",
       "3    Male  27.0                             no   no    no   2.0   no   \n",
       "4    Male  22.0                             no   no    no   2.0   no   \n",
       "\n",
       "         CALC                 MTRANS        obesity_level        BMI  \\\n",
       "0          no  Public_Transportation        Normal_Weight  24.386526   \n",
       "1   Sometimes  Public_Transportation        Normal_Weight  24.238227   \n",
       "2  Frequently  Public_Transportation        Normal_Weight  23.765432   \n",
       "3  Frequently                Walking   Overweight_Level_I  26.851852   \n",
       "4   Sometimes  Public_Transportation  Overweight_Level_II  28.342381   \n",
       "\n",
       "   SedentaryScore  DietScore  \n",
       "0             1.0        4.0  \n",
       "1            -3.0        5.0  \n",
       "2            -1.0        4.0  \n",
       "3            -2.0        5.0  \n",
       "4             0.0        2.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Data:\n",
      "Gender                            0\n",
      "Age                               0\n",
      "family_history_with_overweight    0\n",
      "FAVC                              0\n",
      "SMOKE                             0\n",
      "CH2O                              0\n",
      "SCC                               0\n",
      "CALC                              0\n",
      "MTRANS                            0\n",
      "obesity_level                     0\n",
      "BMI                               0\n",
      "SedentaryScore                    0\n",
      "DietScore                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull().sum()\n",
    "print(\"\\nMissing Data:\")\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender   Age  family_history_with_overweight  FAVC  SMOKE  CH2O  SCC  CALC  \\\n",
      "0       0  21.0                               1     0      0   2.0    0     3   \n",
      "1       0  21.0                               1     0      1   3.0    1     2   \n",
      "2       1  23.0                               1     0      0   2.0    0     1   \n",
      "3       1  27.0                               0     0      0   2.0    0     1   \n",
      "4       1  22.0                               0     0      0   2.0    0     2   \n",
      "\n",
      "   MTRANS  obesity_level        BMI  SedentaryScore  DietScore  \n",
      "0       3              1  24.386526             1.0        4.0  \n",
      "1       3              1  24.238227            -3.0        5.0  \n",
      "2       3              1  23.765432            -1.0        4.0  \n",
      "3       4              5  26.851852            -2.0        5.0  \n",
      "4       3              6  28.342381             0.0        2.0  \n"
     ]
    }
   ],
   "source": [
    "# Label encoding for categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming `data` is your original DataFrame\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = ['Gender', 'family_history_with_overweight','FAVC', \n",
    "                       'SMOKE', 'SCC', 'CALC', 'MTRANS', 'obesity_level']\n",
    "\n",
    "# Create a new DataFrame to store encoded data\n",
    "encoded_data = df.copy()\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for column in categorical_columns:\n",
    "    encoded_data[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Display the newly encoded DataFrame\n",
    "print(encoded_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Example: Ignore warnings globally\n",
    "warnings.filterwarnings('ignore')  # Suppresses all warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoded_data.drop(columns=['obesity_level'])  # Features (all columns except the target)\n",
    "y = encoded_data['obesity_level']                # Target (obesity_level)\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8912529550827423\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.8912529550827423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        56\n",
      "           1       0.96      0.81      0.88        62\n",
      "           2       0.90      0.82      0.86        78\n",
      "           3       0.89      0.93      0.91        58\n",
      "           4       0.89      1.00      0.94        63\n",
      "           5       0.82      0.88      0.84        56\n",
      "           6       0.85      0.82      0.84        50\n",
      "\n",
      "    accuracy                           0.89       423\n",
      "   macro avg       0.89      0.89      0.89       423\n",
      "weighted avg       0.89      0.89      0.89       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "log_model = LogisticRegression(multi_class='multinomial',solver='lbfgs', max_iter=1000, random_state=42)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_predlog=log_model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predlog))\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predlog))\n",
    "print(classification_report(y_test, y_predlog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "Best Hyperparameters: {'C': 1, 'max_iter': 100, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Test Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        56\n",
      "           1       1.00      0.87      0.93        62\n",
      "           2       0.99      0.99      0.99        78\n",
      "           3       0.98      1.00      0.99        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       0.91      0.93      0.92        56\n",
      "           6       0.92      0.96      0.94        50\n",
      "\n",
      "    accuracy                           0.96       423\n",
      "   macro avg       0.96      0.96      0.96       423\n",
      "weighted avg       0.97      0.96      0.96       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'multi_class': ['multinomial', 'ovr'],  # Multi-class handling options\n",
    "    'solver': ['lbfgs', 'newton-cg', 'saga'],  # Solvers suitable for multi-class classification\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength (inverse of regularization)\n",
    "    'max_iter': [100, 500, 1000]  # Number of iterations for convergence\n",
    "}\n",
    "\n",
    "#Initialize Logistic Regression model\n",
    "log_model = LogisticRegression(random_state=42)\n",
    "\n",
    "#Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=log_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Extract best parameters and evaluate model\n",
    "best_params = grid_search.best_params_\n",
    "best_log_model = grid_search.best_estimator_\n",
    "y_pred = best_log_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        56\n",
      "           1       0.94      0.98      0.96        62\n",
      "           2       0.99      0.94      0.96        78\n",
      "           3       0.92      0.98      0.95        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       0.93      0.96      0.95        56\n",
      "           6       0.98      0.94      0.96        50\n",
      "\n",
      "    accuracy                           0.96       423\n",
      "   macro avg       0.96      0.96      0.96       423\n",
      "weighted avg       0.97      0.96      0.96       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Initialize and train the Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier()  # You can tune max_depth and criterion\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Predict on the test set\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Step 3: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6300 candidates, totalling 31500 fits\n",
      "\n",
      "Best Hyperparameters: {'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        56\n",
      "           1       0.94      0.98      0.96        62\n",
      "           2       0.97      0.95      0.96        78\n",
      "           3       0.93      0.98      0.96        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       0.98      0.95      0.96        56\n",
      "           6       0.98      0.98      0.98        50\n",
      "\n",
      "    accuracy                           0.97       423\n",
      "   macro avg       0.97      0.97      0.97       423\n",
      "weighted avg       0.97      0.97      0.97       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the parameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],  # Measures for splitting\n",
    "    'max_depth': [None, 5, 10, 15, 20, 30, 50],  # Range of tree depths\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 10],  # Minimum samples at leaf nodes\n",
    "    'max_features': [None, 'sqrt', 'log2'],  # Features considered for splits\n",
    "    'splitter': ['best', 'random'],  # Splitting strategy\n",
    "    'class_weight': [None, 'balanced']  # Handle class imbalance\n",
    "}\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search CV\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "\n",
    "# Predict and evaluate the best model\n",
    "y_pred_dt = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 0.9810874704491725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        56\n",
      "           1       0.94      0.98      0.96        62\n",
      "           2       1.00      0.99      0.99        78\n",
      "           3       0.98      1.00      0.99        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       0.98      0.93      0.95        56\n",
      "           6       0.96      1.00      0.98        50\n",
      "\n",
      "    accuracy                           0.98       423\n",
      "   macro avg       0.98      0.98      0.98       423\n",
      "weighted avg       0.98      0.98      0.98       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier with HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n",
      "Best Parameters: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Random Forest Classifier with Best Parameters:\n",
      "Accuracy: 0.983451536643026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        56\n",
      "           1       0.95      1.00      0.98        62\n",
      "           2       0.99      0.99      0.99        78\n",
      "           3       0.98      0.98      0.98        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       1.00      0.95      0.97        56\n",
      "           6       0.96      1.00      0.98        50\n",
      "\n",
      "    accuracy                           0.98       423\n",
      "   macro avg       0.98      0.98      0.98       423\n",
      "weighted avg       0.98      0.98      0.98       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Example: Replace X_train, y_train, X_test, y_test with your data\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],      # Maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10],      # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],        # Minimum samples at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],     # Number of features to consider at each split\n",
    "    'criterion': ['gini', 'entropy'],     # Splitting criteria\n",
    "    'class_weight': ['balanced', 'balanced_subsample']  # Handling class imbalance\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best model\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "rf_predictions = best_rf_model.predict(X_test)\n",
    "print(\"\\nRandom Forest Classifier with Best Parameters:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Classifier:\n",
      "Accuracy: 0.9858156028368794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        56\n",
      "           1       0.94      1.00      0.97        62\n",
      "           2       1.00      0.99      0.99        78\n",
      "           3       0.98      1.00      0.99        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       1.00      0.95      0.97        56\n",
      "           6       0.98      1.00      0.99        50\n",
      "\n",
      "    accuracy                           0.99       423\n",
      "   macro avg       0.99      0.99      0.99       423\n",
      "weighted avg       0.99      0.99      0.99       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# XGBoost Classifier\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "print(\"\\nXGBoost Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, xgb_predictions))\n",
    "print(classification_report(y_test, xgb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.2, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'scale_pos_weight': 1, 'subsample': 1.0}\n",
      "\n",
      "Accuracy: 0.99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        56\n",
      "           1       0.95      1.00      0.98        62\n",
      "           2       0.99      0.99      0.99        78\n",
      "           3       0.98      0.98      0.98        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       1.00      0.96      0.98        56\n",
      "           6       0.98      1.00      0.99        50\n",
      "\n",
      "    accuracy                           0.99       423\n",
      "   macro avg       0.99      0.99      0.99       423\n",
      "weighted avg       0.99      0.99      0.99       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],               # Fewer options for tree count\n",
    "    'learning_rate': [0.1, 0.2],             # Focused range for convergence\n",
    "    'max_depth': [5, 7],                     # Reduced tree depth for simplicity\n",
    "    'min_child_weight': [3],                 # Single, commonly used value\n",
    "    'gamma': [0, 0.1],                       # Minimal options for loss reduction\n",
    "    'subsample': [0.7, 1.0],                 # Most effective sampling fractions\n",
    "    'colsample_bytree': [0.7, 1.0],          # Focused range for feature selection\n",
    "    'scale_pos_weight': [1]                  # Standard balance for imbalanced data\n",
    "}\n",
    "\n",
    "# Step 2: Initialize the XGBoost Classifier\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', random_state=42, use_label_encoder=False)\n",
    "\n",
    "# Step 3: Perform Grid Search CV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Get the best parameters and best model\n",
    "best_params = grid_search.best_params_\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "\n",
    "# Step 5: Predict on the test set using the best model\n",
    "xgb_predictions = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, xgb_predictions)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, xgb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine (SVM):\n",
      "Accuracy: 0.9645390070921985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96        56\n",
      "           1       0.95      0.94      0.94        62\n",
      "           2       0.97      0.97      0.97        78\n",
      "           3       0.97      1.00      0.98        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       0.96      0.93      0.95        56\n",
      "           6       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.96       423\n",
      "   macro avg       0.96      0.96      0.96       423\n",
      "weighted avg       0.96      0.96      0.96       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "print(\"\\nSupport Vector Machine (SVM):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'C': 10, 'class_weight': None, 'degree': 2, 'gamma': 0.1, 'kernel': 'rbf', 'shrinking': True}\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        56\n",
      "           1       0.92      0.92      0.92        62\n",
      "           2       0.97      0.99      0.98        78\n",
      "           3       0.98      0.98      0.98        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       0.93      0.95      0.94        56\n",
      "           6       1.00      0.96      0.98        50\n",
      "\n",
      "    accuracy                           0.97       423\n",
      "   macro avg       0.97      0.97      0.97       423\n",
      "weighted avg       0.97      0.97      0.97       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define the parameter grid\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],                       # Focused kernel types\n",
    "    'C': [0.1, 1, 10, 100],                            # Narrowed range of regularization strengths\n",
    "    'gamma': ['scale', 0.01, 0.1],                     # Simplified kernel coefficients\n",
    "    'degree': [2, 3],                                  # Reduced polynomial degrees\n",
    "    'shrinking': [True],                               # Single value (shrinking heuristic often preferred              # One-vs-One strategy (commonly used for SVM)\n",
    "    'class_weight': [None, 'balanced']               # Handle imbalanced class distribution\n",
    "}\n",
    "\n",
    "\n",
    "# Step 2: Initialize the SVC model\n",
    "svc_model = SVC(random_state=42)\n",
    "\n",
    "# Step 3: Perform Grid Search CV\n",
    "grid_search = GridSearchCV(estimator=svc_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Get the best parameters and best model\n",
    "best_params = grid_search.best_params_\n",
    "best_svc_model = grid_search.best_estimator_\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "\n",
    "# Step 5: Predict on the test set using the best model\n",
    "svc_predictions = best_svc_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, svc_predictions)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, svc_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
